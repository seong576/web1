{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict_location_of_retina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JT6V8aSwDQdG2E2Ty9L0GPsKJOuxcwv1",
      "authorship_tag": "ABX9TyP5hBVEzfxahrwE8MvYKqE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seong576/web1/blob/master/Predict_location_of_retina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image To Numpy"
      ],
      "metadata": {
        "id": "7xtdAqDARkRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI2gtgd9U19G"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.io import imread\n",
        "from skimage.transform import pyramid_reduce, resize\n",
        "import os, glob\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/retinal/\"\n",
        "\n",
        "img_list = sorted(glob.glob(path+'Train_img/*.jpg'))\n",
        "mask_list = sorted(glob.glob(path+'Train_Mask/*.png'))\n",
        "row_size =320\n",
        "col_size = 320\n",
        "\n",
        "x_data, y_data = np.empty((2, len(img_list), row_size, col_size , 1), dtype=np.float32)\n",
        "\n",
        "for i, img_path in enumerate(img_list):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, output_shape=(row_size, col_size , 1), preserve_range=True)\n",
        "    x_data[i] = img\n",
        "    \n",
        "for i, img_path in enumerate(mask_list):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, output_shape=(row_size, col_size , 1), preserve_range=True)\n",
        "    y_data[i] = img\n",
        "    \n",
        "y_data /= 255.\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(x_data[12].squeeze(), cmap='gray')\n",
        "ax[1].imshow(y_data[12].squeeze(), cmap='gray')\n",
        "\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1)\n",
        "\n",
        "np.save(path+'x_train.npy', x_train)\n",
        "np.save(path+'y_train.npy', y_train)\n",
        "np.save(path+'x_val.npy', x_val)\n",
        "np.save(path+'y_val.npy', y_val)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##U-net Model"
      ],
      "metadata": {
        "id": "OP6NWW8DRwCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from __future__ import print_function\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Dropout, Conv2D, Conv3D\n",
        "from keras.layers import MaxPooling2D, MaxPooling3D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers import Reshape, Dense, multiply, Add, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from keras import models\n",
        "from keras import callbacks\n",
        "from keras.layers import Input, Activation, Conv2D, Flatten, Dense, MaxPooling2D, Dropout, Add, LeakyReLU, UpSampling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "path = \"/content/drive/MyDrive/retinal/\"\n",
        "\n",
        "x_train = np.load(path+'x_train.npy')\n",
        "y_train = np.load(path+'y_train.npy')\n",
        "x_val = np.load(path+'x_val.npy')\n",
        "y_val = np.load(path+'y_val.npy')\n",
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "inputs = Input(shape=(320, 320, 1))\n",
        "\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2),\n",
        "                                       padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "model = Model(inputs=[inputs], outputs=[conv10])\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss', save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=2, epochs=20,\n",
        "                        verbose=1, shuffle=True,\n",
        "                        validation_data=(x_val, y_val),callbacks=[model_checkpoint])\n",
        "\n",
        "model.save(path+\"Unet\")"
      ],
      "metadata": {
        "id": "vyVGNRA6BWmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Video to Numpy and Prediction"
      ],
      "metadata": {
        "id": "EPEdvjUbR4OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "path = \"/content/drive/MyDrive/retinal/\"\n",
        "mymodel = keras.models.load_model(path+\"Unet\", compile =False)\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(path+\"dhr.mp4\")\n",
        "tensor = []\n",
        "while cap.isOpened():\n",
        "    ret, image = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "    image = cv2.resize(image, (320, 320))\n",
        "    gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    tensor.append(np.asarray(gray_img)[:,:])\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "tensor = np.array(tensor)\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()\n",
        "\n",
        "x_test = tensor\n",
        "#y_test = np.load(path+\"y_test.npy\")\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "\n",
        "img_rows =320\n",
        "img_cols =320\n",
        "def set_view():\n",
        "    total=x_test.shape[0]\n",
        "    print (x_test.shape)\n",
        "    dt_img = np.ndarray((total, img_rows, img_cols), dtype=np.uint8)\n",
        "    rgb_img = np.ndarray((total, img_rows, img_cols, 3), dtype=np.uint8)\n",
        "    for m in range(total):\n",
        "        gray_img = x_test[m]\n",
        "        gray_img = cv2.resize(gray_img, (img_cols, img_rows))\n",
        "\n",
        "        t_img = preds[m,:,:,0]\n",
        "        t_img = cv2.resize(t_img, (img_cols, img_rows))\n",
        "\n",
        "        kernel = np.ones((3,3), np.uint8)\n",
        "        dilated_img = cv2.dilate(128*t_img, kernel, iterations=1)\n",
        "\n",
        "        boundary_img = dilated_img * (1-t_img)\n",
        "\n",
        "        rgb_img[m][:,:,0] = gray_img\n",
        "        rgb_img[m][:,:,1] = np.clip(gray_img + boundary_img, 0, 255)\n",
        "        rgb_img[m][:,:,2] = gray_img\n",
        "    return rgb_img\n",
        "\n",
        "view_imgs ,_ = set_view()\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(path+\"동영상r.mp4\", fourcc, 30, (img_rows,img_cols))\n",
        "print(view_imgs.shape)\n",
        "for i in range(len(view_imgs)):\n",
        "      out.write(np.uint8(view_imgs[i]))\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "TueISSMuHvO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}